### An Encoder-Decoder Model with Attention for Semantic Parsing

A [sequence-to-sequence (seq2seq) model](https://arxiv.org/abs/1606.03622) for Semantic Parsing using Encoder-decoder and Attention as main building blocks.

Dataset: [GeoQuery](https://www.cs.utexas.edu/~ai-lab/pub-view.php?PubID=51437)

For detailed background, refer to ch. 12 and ch. 18 of [Jacob Eisentein](https://jacobeisenstein.github.io/)'s [Introduction to Natural Language Processing](https://mitpress.mit.edu/books/introduction-natural-language-processing), and to ch. 11 and ch. 15 of [Dan Jurafsky](https://web.stanford.edu/~jurafsky/) and [James H. Martin](https://home.cs.colorado.edu/~martin/)'s [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) 


